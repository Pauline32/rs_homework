Thinking1：排序模型按照样本生成方法和损失函数的不同，可以划分成Pointwise, Pairwise, Listwise三类方法，这三类排序方法有何区别
Pointwise排序学习（单点法）：
将文档转化为特征向量，每个文档都是独立的
对于某一个query，它将每个doc分别判断与这个query的相关程度
将docs排序问题转化为了分类（比如相关、不相关）或回归问题（相关程度越大，回归函数的值越大）
从训练数据中学习到的分类或者回归函数对doc打分，打分结果即是搜索结果，CTR可以采用Pointwise方式进行学习，对每一个候选item给出一个评分，基于评分进行排序
仅仅考虑了query和doc之间的关系，而没有考虑排序列表中docs之间的关系

Pairewise排序学习（配对法）：
LTR学习方法之一，将排序问题转换为二元分类问题
接收到用户査询后，返回相关文档列表，确定文档之间的先后顺序关系（多个pair的排序问题）
对于同一查询的相关文档集中，对任何两个不同label的文档，都可以得到一个训练实例（di,dj），如果di>dj则赋值+1，反之-1
没有考虑文档出现在搜索列表中的位置，排在搜索结果前面的文档更为重要，如果靠前的文档出现判断错误，代价会很高

Listwise排序学习（列表法）：
它是将每个Query对应的所有搜索结果列表作为一个训练样例
根据训练样例训练得到最优评分函数F，对应新的查询，评分F对每个文档打分，然后根据得分由高到低排序，即为最终的排序结果
直接考虑整体序列，针对Ranking评价指标（比如MAP, NDCG）进行优化


Thinking2：排序模型按照结构划分，可以分为线性排序模型、树模型、深度学习模型，这些模型都有哪些典型的代表？
线性排序模型：LR
树模型：GBDT
深度学习模型：RankNet

Thinking3：NDCG如何计算
假设搜索回来的6个结果，其相关性分数（REL）分别是 3、2、3、0、1、2
累计增益 CG=3+2+3+0+1+2，只是对相关的分数进行了一个关联的打分，并没有召回的所在位置对排序结果评分对影响
计算DCG
DCG = 3+1.26+1.5+0+0.38+0.71 = 6.86
计算iDCG（理想情况下最大的DCG值）
假设实际召回了8个物品，还有两个结果，第7个相关性为3，第8个相关性为0。那么在理想情况下的相关性分数排序应该是：3、3、3、2、2、1、0、0。计算IDCG@6:
iDCG=3+1.89+1.5+0.86+0.77+0.35 = 8.37
所以最终的 NDCG@6 = 6.86/8.37 = 81.96%


Thinking4：搜索排序和推荐系统的相同和不同之处有哪些
推荐系统，基于历史行为的“猜你喜欢”
搜索排序，基于某Query进行的结果排序，期望用户选中的在排序结果中是靠前的 => 有意识的被动推荐
排序结果都很重要，猜用户想要点击或者booking的item就在结果列表前面
排序学习是个性化结果，用于搜索列表、推荐列表、广告等场景

Thinking5：Listwise排序模型能否应用到推荐系统中
可以
因为排序学习是个性化结果，猜用户想要点击或者booking的item排在列表前面。
只是考虑到性能问题，一般推荐系统用Pointwise模型即可。

